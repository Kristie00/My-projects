# Welcome to my Project page! :wave:

Hi there! Thanks for visiting my GitHub Project page. 
On this page, you'll find a selection of projects that I completed during my time at Green Fox Academy Bootcamp. 
Below you'll find a list of my projects along with descriptions and links to their repositories.

### Part 1: Programing languages
During the first part of my bootcamp, we learned the fundamentals of **Java**. We began by learning how to use Git and the Command Line Interface (CLI). We also learned basic programming concepts such as variables, flow control statements, and basic data structures. We wrote our first functions and learned about debugging, testing, and error exceptions. Additionally, we learned how to read from and write to files. We also learned about the four main theoretical principles of object-oriented programming: abstraction, encapsulation, polymorphism, and inheritance.

In the second part of the bootcamp, we learned **Python**. Since we already had a basic understanding of programming from learning Java, we applied our knowledge to Python. We learned new things such as working with [Flask and Jinja](https://github.com/Kristie00/My-projects/tree/main/Flask%20with%20Jinja) or connecting Python with MSSQL using [pyodbc](https://github.com/Kristie00/My-projects/tree/main/pyodbc).

### Part 2: Databases
Throughout this section, we acquired practical knowledge on utilizing [SQL](https://github.com/Kristie00/My-projects/tree/main/SQL%20exercises) for manipulating relational databases in MSSQL. 
Furthermore, we also gained proficiency in managing document-oriented database [MongoDB](https://github.com/Kristie00/My-projects/tree/main/MongoDB) through the usage of MongoDB Query Language.

### Part 3: Trying out Data Engineering Tools
In this section, we gained our first experience working with data engineering tools, specifically [Kafka](https://github.com/Kristie00/My-projects/tree/main/Kafka) and [Airflow](https://github.com/Kristie00/My-projects/tree/main/Airflow/First%20DAG). 
Using Kafka, we developed proficiency in creating producers and consumers, as well as in generating data files. In the case of Airflow, we gained familiarity with writing and executing DAGs.

### Part 4: Projects
In this section, I would like to present some of the projects I did during my bootcamp. These projects helped me to use what I learned in class about different technologies and mainly Python. I'm excited to share these projects because they show how much I enjoy coding.
+ [0th Project- My first website](https://github.com/Kristie00/My-projects/tree/main/0th%20project-%20My%20first%20website)
  + Prior to the bootcamp, I had the chance to get a taste of programming by creating my first website about myself. This initial project served as a foundation for my subsequent learning, and helped me gain familiarity with basic HTML and CSS.
+ [Project Movies](https://github.com/Kristie00/My-projects/tree/main/Project%20Movies%20with%20REST%20API%2C%20pyodbc)
  + My project involved using Python, Flask, Jinja, and SQL to develop a web page that can be accessed locally. By leveraging the pyodbc module, I was able to connect the web page to an MSSQL database, which allowed me to use SQL queries to manipulate and retrieve data from the database, according to used HTTP method.
+ [Preparation for Second Exam](https://github.com/Kristie00/My-projects/tree/main/Templates%20for%20exam)
  + In training for the Second Data Engineering Exam I developed a workflow using Airflow to extract data from a REST API, transform it, and store it in a database. I implemented processes to transfer and transform data between MSSQL tables, and between MSSQL and MongoDB. Also managed data flow from files to MSSQL, followed by transformation and storage in MongoDB. 
+ [Second Exam](https://github.com/Kristie00/My-projects/tree/main/Exam%20from%20second%20phase-%20ETL%20pipeline)
  + Check out my solution of the second exam. I had to create a ELT pipeline which collects information about Airports using Airflow. I had to get data from REST API and dataset about airports, transform and load it to a MSSQL database and MongoDB. Final part was answering the questions to check, if I could use correct queries and if my pipeline works correct.
+ [Final Project](https://github.com/Kristie00/My-projects/tree/main/Project-%20ELT%20pipeline)
  + In my final project, I utilized Airbyte on Docker for data extraction from Google Spreadsheets and public datasets. I used Big Query for data storage and dbt for data transformation, automated processes with Airflow, visualized and analyzed cleaned data using PowerBI to determine the most used data engineering technology in 2021.

Thank you for checking out my projects! If you have any questions or feedback, feel free to reach out to me.
